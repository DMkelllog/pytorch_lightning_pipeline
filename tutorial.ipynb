{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import LitModel\n",
    "import argparse\n",
    "\n",
    "import tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# argpaser\n",
    "parser = argparse.ArgumentParser(description='PyTorch Lightning Example')\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--num_tta', type=int, default=10)\n",
    "parser.add_argument('--es_patience', type=int, default=10)\n",
    "parser.add_argument('--num_workers', type=int, default=4)\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--progress_bar', type=bool, default=False)\n",
    "parser.add_argument('--checkpoint_verbose', type=bool, default=False)\n",
    "parser.add_argument('--earlystopping_verbose', type=bool, default=False)\n",
    "args = parser.parse_args([]) # default settings\n",
    "\n",
    "seed = args.seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentation = T.Compose([T.ToTensor(),\n",
    "                                T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "                                T.RandomHorizontalFlip(),\n",
    "                                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "no_augmentation = T.Compose([T.ToTensor(),\n",
    "                                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=augmentation\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=no_augmentation\n",
    ")\n",
    "\n",
    "test_data_tta = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 [train_loss: 1.2845 val_loss: 1.1349] [train_acc: 0.5568 val_acc: 0.6136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Restoring states from the checkpoint path at /home/kang/pytorch_lightning_pipeline/models/epoch=0-step=703.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/kang/pytorch_lightning_pipeline/models/epoch=0-step=703.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6662999987602234, 'test_loss': 1.0146721601486206}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/kang/anaconda3/envs/torch/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.0146721601486206, 'test_acc': 0.6662999987602234}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset, val_dataset = random_split(training_data, [45000, 5000])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "test_dataloader_tta = DataLoader(test_data_tta, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=args.es_patience, verbose=args.earlystopping_verbose, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint('models', save_top_k=1, monitor='val_loss', verbose=args.checkpoint_verbose, mode='min')\n",
    "\n",
    "model = LitModel(architecture, args.learning_rate)\n",
    "trainer = Trainer(max_epochs=args.epochs, \n",
    "                gpus=1,\n",
    "                enable_progress_bar=args.progress_bar,\n",
    "                logger=logger, \n",
    "                callbacks=[early_stop_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/kang/pytorch_lightning_pipeline/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:662: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 [train_loss: 1.2776 val_loss: 1.1083] [train_acc: 0.5564 val_acc: 0.6204]\n",
      "epoch:  1 [train_loss: 0.9953 val_loss: 0.9392] [train_acc: 0.6601 val_acc: 0.6750]\n",
      "epoch:  2 [train_loss: 0.8981 val_loss: 0.8492] [train_acc: 0.6922 val_acc: 0.7008]\n",
      "epoch:  3 [train_loss: 0.8332 val_loss: 0.8260] [train_acc: 0.7152 val_acc: 0.7158]\n",
      "epoch:  4 [train_loss: 0.8103 val_loss: 0.8082] [train_acc: 0.7233 val_acc: 0.7182]\n",
      "epoch:  5 [train_loss: 0.7589 val_loss: 0.8088] [train_acc: 0.7404 val_acc: 0.7272]\n",
      "epoch:  6 [train_loss: 0.7475 val_loss: 0.6881] [train_acc: 0.7443 val_acc: 0.7610]\n",
      "epoch:  7 [train_loss: 0.7145 val_loss: 0.8290] [train_acc: 0.7546 val_acc: 0.7322]\n",
      "epoch:  8 [train_loss: 0.6736 val_loss: 0.7183] [train_acc: 0.7682 val_acc: 0.7526]\n",
      "epoch:  9 [train_loss: 0.6496 val_loss: 0.6776] [train_acc: 0.7768 val_acc: 0.7706]\n",
      "epoch: 10 [train_loss: 0.6192 val_loss: 0.6668] [train_acc: 0.7867 val_acc: 0.7686]\n",
      "epoch: 11 [train_loss: 0.6167 val_loss: 0.6596] [train_acc: 0.7872 val_acc: 0.7698]\n",
      "epoch: 12 [train_loss: 0.6024 val_loss: 0.6186] [train_acc: 0.7925 val_acc: 0.7856]\n",
      "epoch: 13 [train_loss: 0.5779 val_loss: 0.6931] [train_acc: 0.7985 val_acc: 0.7650]\n",
      "epoch: 14 [train_loss: 0.5855 val_loss: 0.6100] [train_acc: 0.7998 val_acc: 0.7894]\n",
      "epoch: 15 [train_loss: 0.5655 val_loss: 0.6780] [train_acc: 0.8045 val_acc: 0.7686]\n",
      "epoch: 16 [train_loss: 0.6180 val_loss: 0.6019] [train_acc: 0.7874 val_acc: 0.7918]\n",
      "epoch: 17 [train_loss: 0.5298 val_loss: 0.5963] [train_acc: 0.8160 val_acc: 0.7976]\n",
      "epoch: 18 [train_loss: 0.5374 val_loss: 0.6197] [train_acc: 0.8141 val_acc: 0.7996]\n",
      "epoch: 19 [train_loss: 0.5059 val_loss: 0.5951] [train_acc: 0.8250 val_acc: 0.7978]\n",
      "epoch: 20 [train_loss: 0.5328 val_loss: 0.7369] [train_acc: 0.8156 val_acc: 0.7570]\n",
      "epoch: 21 [train_loss: 0.5180 val_loss: 0.5707] [train_acc: 0.8212 val_acc: 0.8026]\n",
      "epoch: 22 [train_loss: 0.5023 val_loss: 0.5886] [train_acc: 0.8247 val_acc: 0.8012]\n",
      "epoch: 23 [train_loss: 0.4698 val_loss: 0.5793] [train_acc: 0.8375 val_acc: 0.8018]\n",
      "epoch: 24 [train_loss: 0.5135 val_loss: 0.5765] [train_acc: 0.8220 val_acc: 0.8022]\n",
      "epoch: 25 [train_loss: 0.4759 val_loss: 0.5503] [train_acc: 0.8355 val_acc: 0.8114]\n",
      "epoch: 26 [train_loss: 0.4575 val_loss: 0.5790] [train_acc: 0.8403 val_acc: 0.8000]\n",
      "epoch: 27 [train_loss: 0.4504 val_loss: 0.5678] [train_acc: 0.8421 val_acc: 0.8038]\n",
      "epoch: 28 [train_loss: 0.4430 val_loss: 0.5889] [train_acc: 0.8450 val_acc: 0.8008]\n",
      "epoch: 29 [train_loss: 0.4313 val_loss: 0.5246] [train_acc: 0.8486 val_acc: 0.8202]\n",
      "epoch: 30 [train_loss: 0.4270 val_loss: 0.5634] [train_acc: 0.8504 val_acc: 0.8078]\n",
      "epoch: 31 [train_loss: 0.4170 val_loss: 0.5620] [train_acc: 0.8535 val_acc: 0.8174]\n",
      "epoch: 32 [train_loss: 0.4103 val_loss: 0.5749] [train_acc: 0.8559 val_acc: 0.8088]\n",
      "epoch: 33 [train_loss: 0.4304 val_loss: 0.6729] [train_acc: 0.8486 val_acc: 0.7962]\n",
      "epoch: 34 [train_loss: 0.4318 val_loss: 0.5672] [train_acc: 0.8499 val_acc: 0.8112]\n",
      "epoch: 35 [train_loss: 0.4308 val_loss: 0.6023] [train_acc: 0.8502 val_acc: 0.8000]\n",
      "Epoch    36: reducing learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 36 [train_loss: 0.4024 val_loss: 0.5374] [train_acc: 0.8582 val_acc: 0.8240]\n",
      "epoch: 37 [train_loss: 0.3432 val_loss: 0.5709] [train_acc: 0.8796 val_acc: 0.8154]\n",
      "epoch: 38 [train_loss: 0.3340 val_loss: 0.6827] [train_acc: 0.8824 val_acc: 0.8126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:907: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1399: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  f\"`.{fn}(ckpt_path=None)` was called without a model.\"\n",
      "Restoring states from the checkpoint path at /home/kang/pytorch_lightning_pipeline/models/epoch=29-step=21119.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/kang/pytorch_lightning_pipeline/models/epoch=29-step=21119.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 [train_loss: 0.3434 val_loss: 0.5290] [train_acc: 0.8783 val_acc: 0.8290]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.8431000113487244, 'test_loss': 0.47976747155189514}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.47976747155189514, 'test_acc': 0.8431000113487244}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 10%|█         | 1/10 [00:01<00:12,  1.38s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 20%|██        | 2/10 [00:02<00:10,  1.35s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 30%|███       | 3/10 [00:04<00:09,  1.34s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 40%|████      | 4/10 [00:05<00:08,  1.35s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 50%|█████     | 5/10 [00:06<00:06,  1.34s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 60%|██████    | 6/10 [00:08<00:05,  1.34s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 70%|███████   | 7/10 [00:09<00:04,  1.35s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 80%|████████  | 8/10 [00:10<00:02,  1.35s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 90%|█████████ | 9/10 [00:12<00:01,  1.35s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA accuracy: 0.8527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tta_pred_list = []\n",
    "for _ in tqdm(range(args.num_tta)):\n",
    "    y_hat = torch.vstack(trainer.predict(model=model, dataloaders=test_dataloader_tta))\n",
    "    tta_pred_list.append(y_hat)\n",
    "tta_pred_mean = torch.stack(tta_pred_list).mean(0)\n",
    "\n",
    "tta_acc = np.mean(tta_pred_mean.argmax(1).numpy() == np.array(test_data.targets))\n",
    "print(f\"TTA accuracy: {tta_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67279a16936c44c66ab678de41f1260360b345454ec17353bfa5d06d9ac761b8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
