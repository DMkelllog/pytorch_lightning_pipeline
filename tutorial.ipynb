{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import LitModel\n",
    "import argparse\n",
    "\n",
    "import tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# argpaser\n",
    "parser = argparse.ArgumentParser(description='PyTorch Lightning Example')\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--num_tta', type=int, default=10)\n",
    "parser.add_argument('--es_patience', type=int, default=10)\n",
    "parser.add_argument('--num_workers', type=int, default=4)\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--progress_bar', type=bool, default=False)\n",
    "parser.add_argument('--checkpoint_verbose', type=bool, default=False)\n",
    "parser.add_argument('--earlystopping_verbose', type=bool, default=False)\n",
    "args = parser.parse_args([]) # default settings\n",
    "\n",
    "seed = args.seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentation = T.Compose([T.ToTensor(),\n",
    "                                T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "                                T.RandomHorizontalFlip(),\n",
    "                                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "no_augmentation = T.Compose([T.ToTensor(),\n",
    "                                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=augmentation\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=no_augmentation\n",
    ")\n",
    "\n",
    "test_data_tta = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset, val_dataset = random_split(training_data, [45000, 5000])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "test_dataloader_tta = DataLoader(test_data_tta, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False)\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=args.es_patience, verbose=args.earlystopping_verbose, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint('models', save_top_k=1, monitor='val_loss', verbose=args.checkpoint_verbose, mode='min')\n",
    "\n",
    "model = LitModel(architecture, args.learning_rate)\n",
    "trainer = Trainer(max_epochs=args.epochs, \n",
    "                gpus=1,\n",
    "                enable_progress_bar=args.progress_bar,\n",
    "                logger=logger, \n",
    "                callbacks=[early_stop_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/kang/pytorch_lightning_pipeline/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:662: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 [train_loss: 1.2603 val_loss: 1.1226] [train_acc: 0.5652 val_acc: 0.6232]\n",
      "epoch:  1 [train_loss: 0.9849 val_loss: 0.9376] [train_acc: 0.6636 val_acc: 0.6832]\n",
      "epoch:  2 [train_loss: 0.8765 val_loss: 0.8520] [train_acc: 0.6982 val_acc: 0.7066]\n",
      "epoch:  3 [train_loss: 0.8304 val_loss: 0.8452] [train_acc: 0.7139 val_acc: 0.7008]\n",
      "epoch:  4 [train_loss: 0.7667 val_loss: 0.9281] [train_acc: 0.7371 val_acc: 0.6906]\n",
      "epoch:  5 [train_loss: 0.7856 val_loss: 0.7251] [train_acc: 0.7302 val_acc: 0.7554]\n",
      "epoch:  6 [train_loss: 0.7161 val_loss: 0.7642] [train_acc: 0.7546 val_acc: 0.7436]\n",
      "epoch:  7 [train_loss: 0.6845 val_loss: 0.7487] [train_acc: 0.7619 val_acc: 0.7424]\n",
      "epoch:  8 [train_loss: 0.6563 val_loss: 0.7084] [train_acc: 0.7743 val_acc: 0.7588]\n",
      "epoch:  9 [train_loss: 0.6362 val_loss: 0.8137] [train_acc: 0.7818 val_acc: 0.7238]\n",
      "epoch: 10 [train_loss: 0.6158 val_loss: 0.6904] [train_acc: 0.7854 val_acc: 0.7592]\n",
      "epoch: 11 [train_loss: 0.6574 val_loss: 0.7328] [train_acc: 0.7766 val_acc: 0.7470]\n",
      "epoch: 12 [train_loss: 0.5856 val_loss: 0.6552] [train_acc: 0.7965 val_acc: 0.7710]\n",
      "epoch: 13 [train_loss: 0.5688 val_loss: 0.6669] [train_acc: 0.8045 val_acc: 0.7704]\n",
      "epoch: 14 [train_loss: 0.5698 val_loss: 0.6670] [train_acc: 0.8026 val_acc: 0.7748]\n",
      "epoch: 15 [train_loss: 0.5565 val_loss: 0.6552] [train_acc: 0.8080 val_acc: 0.7750]\n",
      "epoch: 16 [train_loss: 0.5269 val_loss: 0.6580] [train_acc: 0.8170 val_acc: 0.7694]\n",
      "epoch: 17 [train_loss: 0.5153 val_loss: 0.6302] [train_acc: 0.8204 val_acc: 0.7930]\n",
      "epoch: 18 [train_loss: 0.5156 val_loss: 0.6279] [train_acc: 0.8213 val_acc: 0.7834]\n",
      "epoch: 19 [train_loss: 0.5154 val_loss: 0.6498] [train_acc: 0.8221 val_acc: 0.7790]\n",
      "epoch: 20 [train_loss: 0.5141 val_loss: 0.6089] [train_acc: 0.8230 val_acc: 0.7930]\n",
      "epoch: 21 [train_loss: 0.4942 val_loss: 0.6488] [train_acc: 0.8294 val_acc: 0.7852]\n",
      "epoch: 22 [train_loss: 0.4697 val_loss: 0.7642] [train_acc: 0.8359 val_acc: 0.7762]\n",
      "epoch: 23 [train_loss: 0.4716 val_loss: 0.6168] [train_acc: 0.8370 val_acc: 0.7948]\n",
      "epoch: 24 [train_loss: 0.4654 val_loss: 0.6619] [train_acc: 0.8390 val_acc: 0.7778]\n",
      "epoch: 25 [train_loss: 0.4492 val_loss: 0.6381] [train_acc: 0.8413 val_acc: 0.7936]\n",
      "epoch: 26 [train_loss: 0.4373 val_loss: 0.6617] [train_acc: 0.8470 val_acc: 0.7860]\n",
      "Epoch    27: reducing learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 27 [train_loss: 0.3853 val_loss: 0.5540] [train_acc: 0.8656 val_acc: 0.8154]\n",
      "epoch: 28 [train_loss: 0.3605 val_loss: 0.5645] [train_acc: 0.8727 val_acc: 0.8158]\n",
      "epoch: 29 [train_loss: 0.3490 val_loss: 0.5594] [train_acc: 0.8772 val_acc: 0.8168]\n",
      "epoch: 30 [train_loss: 0.3484 val_loss: 0.5810] [train_acc: 0.8774 val_acc: 0.8074]\n",
      "epoch: 31 [train_loss: 0.3425 val_loss: 0.5693] [train_acc: 0.8786 val_acc: 0.8122]\n",
      "epoch: 32 [train_loss: 0.3883 val_loss: 0.7924] [train_acc: 0.8642 val_acc: 0.8048]\n",
      "epoch: 33 [train_loss: 0.3415 val_loss: 0.5818] [train_acc: 0.8816 val_acc: 0.8140]\n",
      "Epoch    34: reducing learning rate of group 0 to 2.5000e-04.\n",
      "epoch: 34 [train_loss: 0.2972 val_loss: 0.5832] [train_acc: 0.8954 val_acc: 0.8148]\n",
      "epoch: 35 [train_loss: 0.2884 val_loss: 0.6040] [train_acc: 0.8974 val_acc: 0.8318]\n",
      "epoch: 36 [train_loss: 0.2858 val_loss: 0.6108] [train_acc: 0.8990 val_acc: 0.8214]\n",
      "epoch: 37 [train_loss: 0.2838 val_loss: 0.8998] [train_acc: 0.8993 val_acc: 0.8138]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:907: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/home/kang/anaconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1399: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  f\"`.{fn}(ckpt_path=None)` was called without a model.\"\n",
      "Restoring states from the checkpoint path at /home/kang/pytorch_lightning_pipeline/models/epoch=27-step=19711.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/kang/pytorch_lightning_pipeline/models/epoch=27-step=19711.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.8515999913215637, 'test_loss': 0.4361374080181122}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4361374080181122, 'test_acc': 0.8515999913215637}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 10%|█         | 1/10 [00:01<00:12,  1.40s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 20%|██        | 2/10 [00:02<00:11,  1.38s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 30%|███       | 3/10 [00:04<00:09,  1.38s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 40%|████      | 4/10 [00:05<00:08,  1.38s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 50%|█████     | 5/10 [00:06<00:06,  1.38s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 60%|██████    | 6/10 [00:08<00:05,  1.37s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 70%|███████   | 7/10 [00:09<00:04,  1.36s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 80%|████████  | 8/10 [00:11<00:02,  1.42s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      " 90%|█████████ | 9/10 [00:12<00:01,  1.40s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tta_pred_list = []\n",
    "for _ in tqdm(range(args.num_tta)):\n",
    "    y_hat = torch.vstack(trainer.predict(model=model, dataloaders=test_dataloader_tta))\n",
    "    tta_pred_list.append(y_hat)\n",
    "tta_pred_mean = torch.stack(tta_pred_list).mean(0)\n",
    "\n",
    "tta_acc = np.mean(tta_pred_mean.argmax(1).numpy() == np.array(test_data.targets))\n",
    "print(f\"TTA accuracy: {tta_acc}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67279a16936c44c66ab678de41f1260360b345454ec17353bfa5d06d9ac761b8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
